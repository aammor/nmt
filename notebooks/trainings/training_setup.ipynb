{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9705ce7d",
   "metadata": {},
   "source": [
    "Notebook that show the training setup workflow\n",
    "Remark : rather than splitting this notebook into multiple files and test them, we can\n",
    "avoid this time consumming operation by parametrizing the notebook and testing it using ploomber \n",
    "(https://ploomber.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a1e01",
   "metadata": {
    "tags": []
   },
   "source": [
    "### I) define hyper_parameters, datasets, and IO operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f98dcdb4",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# convention : all new inputs parameters for the notebbok through papermil,\n",
    "# that are progressivelt added have a default value, equal to the one tha would be used in\n",
    "# order obtain the same results of scripts\n",
    "\n",
    "# two types of inputs: \n",
    "# inputs that influences the training (e.g hyper-paramteres, dataset set and splitting)\n",
    "# inputs that controls state of training (reset it or load from)\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d348c07-d559-4871-90cd-747caa276b94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_model_and_dependencies = paths.path_model_and_dependencies\n",
    "\n",
    "if train_state_control.load_from_backup:\n",
    "    assert Path(path_model_and_dependencies).exists(),f\"back_up at path : {path_model_and_dependencies} doesn't exists\"\n",
    "    back_up = torch.load(path_model_and_dependencies)\n",
    "    back_up_train_state = back_up[\"model_training_state\"]\n",
    "    # add here routines to check the if the given parameters are coherent ith the values from the back\n",
    "    # up maybe using the notebookRunner class, that would handle this resposability\n",
    "    print(\"loaded backup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6406df-82ba-4ddd-ba0f-5b8814bef276",
   "metadata": {},
   "source": [
    "init or load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f8047e7-be63-4d39-9820-9c3f95cfc92a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from translation_machine.models import transformer_mod\n",
    "from translation_machine import sentence_mod\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "if train_state_control.load_from_backup:\n",
    "    model_inputs = back_up_train_state[\"model_inputs\"]\n",
    "else:\n",
    "    model_inputs = {\n",
    "        \"d_model\":simple_hp.d_model,\n",
    "        \"vocab_src\":sentence_mod.EnglishSentence.vocab,\n",
    "        \"vocab_tgt\":sentence_mod.FrenchSentence.vocab,\n",
    "    }\n",
    "\n",
    "model = transformer_mod.TransformerForSeq2Seq(**model_inputs)\n",
    "    \n",
    "if train_state_control.load_from_backup:\n",
    "    # once we choose to load the model, it is always loaded from backup\n",
    "    model.load_state_dict(back_up_train_state[\"model_params\"])\n",
    "    print(\"loaded model\")\n",
    "\n",
    "# loading(transfering) to the device\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2b980af-8fbb-4213-b208-4329cc96591c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = opt_params.unlinked_optimizer(model.parameters())\n",
    "scheduler = opt_params.unlinked_scheduler(optimizer)\n",
    "\n",
    "if train_state_control.load_from_backup and train_state_control.restore_optimizer:\n",
    "    optimizer.load_state_dict(back_up[\"model_training_state\"][\"optimizer\"])\n",
    "    scheduler.load_state_dict(back_up[\"model_training_state\"][\"scheduler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60cba849-ff81-4192-8456-77352ae41e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "if train_state_control.load_from_backup:\n",
    "    losses = back_up[\"results\"][\"losses\"]\n",
    "    metrics = back_up[\"results\"][\"metrics\"]\n",
    "    best_loss_val_mean = np.min(losses[\"val\"])\n",
    "else:\n",
    "    losses = {\"train\":[],\"val\":[]}\n",
    "    metrics = {\"train\":[],\"val\":[]}\n",
    "    best_loss_val_mean = np.inf\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c310cfa-9bbf-4cf8-a340-cbbb6f7303a4",
   "metadata": {},
   "source": [
    "# II) Load the dataset (as pairs of plain text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80f71a68-2e7e-4e29-bf84-4d01b0876df9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 177210)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from translation_machine import dataset_mod\n",
    "\n",
    "whole_dataset_raw = dataset_mod.DatasetFromTxt(paths.path_dataset)\n",
    "\n",
    "idxs_whole = np.arange(dset_truncation.limit_length)\n",
    "dataset_raw = torch.utils.data.Subset(whole_dataset_raw,idxs_whole)\n",
    "len(dataset_raw),len(whole_dataset_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7ab5a26-552f-499d-9835-5fafd70e4198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remark : the responsability to split the dataset is done outside of this notebook\n",
    "from pathlib import Path\n",
    "\n",
    "if dset_truncation.use_splitting:\n",
    "    path_dataset_splitting = paths.path_dataset_splitting\n",
    "    path_idxs_train = str(Path(path_dataset_splitting).joinpath(\"idxs_train.npy\"))\n",
    "    path_idxs_val = str(Path(path_dataset_splitting).joinpath(\"idxs_val.npy\"))\n",
    "    path_idxs_test = str(Path(path_dataset_splitting).joinpath(\"idxs_test.npy\"))\n",
    "\n",
    "    idxs_train = np.load(path_idxs_train)\n",
    "    idxs_val = np.load(path_idxs_val)\n",
    "    idxs_test = np.load(path_idxs_test)\n",
    "\n",
    "    idxs_train,idxs_val,idxs_test = [[idx for idx in idxs if idx<len(whole_dataset)] for idxs in [idxs_train,idxs_val,idxs_test]]\n",
    "    idxs_train = list(set(idxs_whole).intersection(set(idxs_train)))\n",
    "    idxs_val = list(set(idxs_whole).intersection(set(idxs_val)))\n",
    "    idxs_test = list(set(idxs_whole).intersection(set(idxs_test)))\n",
    "    \n",
    "    idxs_train_val = list(set(idxs_train).intersection(set(idxs_val)))\n",
    "\n",
    "    \n",
    "    train_dataset_raw = torch.utils.data.Subset(dataset_raw,idxs_train)\n",
    "    val_dataset_raw = torch.utils.data.Subset(dataset_raw,idxs_val)\n",
    "    test_dataset_raw = torch.utils.data.Subset(dataset_raw,idxs_test)\n",
    "    train_val_dataset = torch.utils.data.ChainDataset(train_dataset_raw,val_dataset_raw)\n",
    "\n",
    "else:\n",
    "    idxs_train_val = np.arange(len(dataset_raw))\n",
    "\n",
    "    train_dataset_raw = dataset_raw\n",
    "    val_dataset_raw = dataset_raw\n",
    "    test_dataset_raw = dataset_raw\n",
    "    train_val_dataset = dataset_raw\n",
    "\n",
    "    \n",
    "len(train_dataset_raw),len(val_dataset_raw),len(test_dataset_raw),len(train_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f543e98c-36ca-4709-9bcf-5d37c1735f48",
   "metadata": {},
   "source": [
    "# III) Load the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b81ccab-bcd2-4bf7-8e7a-f7e1010a0bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing cell: 2:   0%|                                 | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing cell: 11: 100%|███████████████████████| 13/13 [00:01<00:00,  6.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19, 12)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch,numpy as np\n",
    "from ploomber_engine.ipython import PloomberClient\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "\n",
    "from translation_machine.models import transformer_mod\n",
    "from translation_machine import dataset_mod,sentence_mod\n",
    "\n",
    "        \n",
    "if dset_truncation.recompute_vocabulary:\n",
    "    # initialize client\n",
    "    client = PloomberClient.from_path(Path(\"../create_vocabulary.ipynb\"),\"../\")\n",
    "    train_setup = client.get_namespace(dict(train_val_dataset=train_val_dataset,\n",
    "                                           path_language_info=paths.path_language_info))\n",
    "    #in case of use_splitting=False, we feed the whole dataset to the pipeline\n",
    "\n",
    "language_info = torch.load(paths.path_language_info)\n",
    "vocab_french = language_info[\"french\"][\"vocab\"]\n",
    "vocab_english = language_info[\"english\"][\"vocab\"]\n",
    "\n",
    "\n",
    "len(vocab_french),len(vocab_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dfffb0-e6ab-443d-ab08-f5560250518f",
   "metadata": {},
   "source": [
    " convert datasets to a custom dataset, taking into account the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5017c85e-667b-4711-9a55-906eac4598ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dsets = []\n",
    "for dset in [train_dataset_raw,val_dataset_raw,test_dataset_raw]:\n",
    "    dsets.append(list(dataset_mod.SentenceDataSet(dset,\n",
    "                                                  sentence_type_src=sentence_mod.EnglishSentence,\n",
    "                                                  sentence_type_dst=sentence_mod.FrenchSentence)))\n",
    "train_dataset,val_dataset,test_dataset = dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93aecd31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 9)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_from_file = False\n",
    "if max_length_from_file:\n",
    "    max_length_french = language_info[\"french\"][\"max_sentence_train_val\"]\n",
    "    max_length_english = language_info[\"english\"][\"max_sentence_train_val\"]\n",
    "else:# get max length from current dataset, which is prefered\n",
    "    import itertools\n",
    "    tmp = [(len(el[0]),len(el[1])) for el in train_val_dataset]\n",
    "    a,b = zip(*tmp)\n",
    "    max_length_english  = max(a)\n",
    "    max_length_french = max(b)\n",
    "    \n",
    "max_length_english,max_length_french"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb11c95",
   "metadata": {},
   "source": [
    "### VI) dataloader construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb015efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from translation_machine import collate_fn_mod\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "collate_fn = collate_fn_mod.get_collate_fn(max_length_english,max_length_french)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset,batch_size=simple_hp.batch_size,\n",
    "                               shuffle=True,collate_fn=collate_fn)\n",
    "val_data_loader = DataLoader(val_dataset,batch_size=simple_hp.batch_size,\n",
    "                             shuffle=True,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b32119b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import optim,nn\n",
    "\n",
    "\n",
    "baseline_loss = nn.CrossEntropyLoss(reduction=\"sum\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e4775-5ffb-4cff-a730-5b0557cad273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
