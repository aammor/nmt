{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9705ce7d",
   "metadata": {},
   "source": [
    "Notebook that show the training setup workflow\n",
    "Remark : rather than splitting this notebook into multiple files and test them, we can\n",
    "avoid this time consumming operation by parametrizing the notebook and testing it using ploomber \n",
    "(https://ploomber.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a1e01",
   "metadata": {
    "tags": []
   },
   "source": [
    "### I) define hyper_parameters, datasets, and IO operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98dcdb4",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# convention : all new inputs parameters for the notebbok through papermil,\n",
    "# that are progressivelt added have a default value, equal to the one tha would be used in\n",
    "# order obtain the same results of scripts\n",
    "\n",
    "# two types of inputs: \n",
    "# inputs that influences the training (e.g hyper-paramteres, dataset set and splitting)\n",
    "# inputs that controls state of training (reset it or load from)\n",
    "import torch\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab1efc-75be-4996-9be6-82d8b99237c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model_and_dependencies = paths.path_model_and_dependencies\n",
    "\n",
    "if train_state_control.load_from_backup:\n",
    "    assert Path(path_model_and_dependencies).exists(),f\"back_up at path : {path_model_and_dependencies} doesn't exists\"\n",
    "    back_up = torch.load(path_model_and_dependencies)\n",
    "    back_up_train_state = back_up[\"model_training_state\"]\n",
    "    # add here routines to check the if the given parameters are coherent ith the values from the back\n",
    "    # up maybe using the notebookRunner class, that would handle this resposability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6406df-82ba-4ddd-ba0f-5b8814bef276",
   "metadata": {},
   "source": [
    "init or load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8047e7-be63-4d39-9820-9c3f95cfc92a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from translation_machine.models import transformer_mod\n",
    "from translation_machine import sentence_mod\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "if train_state_control.load_from_backup:\n",
    "    model_inputs = back_up_train_state[\"model_inputs\"]\n",
    "else:\n",
    "    model_inputs = {\n",
    "        \"d_model\":simple_hp.d_model,\n",
    "        \"vocab_src\":sentence_mod.EnglishSentence.vocab,\n",
    "        \"vocab_tgt\":sentence_mod.FrenchSentence.vocab,\n",
    "    }\n",
    "\n",
    "model = transformer_mod.TransformerForSeq2Seq(**model_inputs)\n",
    "    \n",
    "if train_state_control.load_from_backup:\n",
    "    # once we choose to load the model, it is always loaded from backup\n",
    "    model.load_state_dict(back_up_train_state[\"model_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c37d6-12b2-45e7-9446-5ed04eccbb84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#optimizer.link(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b980af-8fbb-4213-b208-4329cc96591c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = opt_params.unlinked_optimizer(model.parameters())\n",
    "scheduler = opt_params.unlinked_scheduler(optimizer)\n",
    "\n",
    "if train_state_control.load_from_backup and train_state_control.restore_optimizer:\n",
    "    optimizer.load_state_dict(back_up[\"model_training_state\"][\"optimizer\"])\n",
    "    scheduler.load_state_dict(back_up[\"model_training_state\"][\"scheduler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cba849-ff81-4192-8456-77352ae41e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_state_control.load_from_backup:\n",
    "    losses = back_up[\"results\"][\"losses\"]\n",
    "    metrics = back_up[\"results\"][\"metrics\"]\n",
    "else:\n",
    "    losses = {\"train\":[],\"val\":[]}\n",
    "    metrics = {\"train\":[],\"val\":[]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba75435-4269-4466-b7a9-b6997288369f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from translation_machine.models import transformer_mod\n",
    "from translation_machine import sentence_mod\n",
    "\n",
    "if train_state_control.load_from_backup:\n",
    "    model_inputs = back_up[\"model_training_state\"][\"model_inputs\"]\n",
    "else:\n",
    "    model_inputs = {\n",
    "        \"d_model\":simple_hp.d_model,\n",
    "        \"vocab_src\":sentence_mod.EnglishSentence.vocab,\n",
    "        \"vocab_tgt\":sentence_mod.FrenchSentence.vocab,\n",
    "    }\n",
    "\n",
    "model = transformer_mod.TransformerForSeq2Seq(**model_inputs)\n",
    "\n",
    "if train_state_control.load_from_backup:\n",
    "    model.load_state_dict(back_up_train_state[\"model_params\"])\n",
    "    print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdcd8e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# II) load the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76840b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from translation_machine import dataset_mod,sentence_mod\n",
    "\n",
    "import torch,numpy as np\n",
    "\n",
    "language_info = torch.load(paths.path_language_info)\n",
    "\n",
    "vocab_french = language_info[\"french\"][\"vocab\"]\n",
    "vocab_english = language_info[\"english\"][\"vocab\"]\n",
    "\n",
    "\n",
    "len(vocab_french),len(vocab_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c310cfa-9bbf-4cf8-a340-cbbb6f7303a4",
   "metadata": {},
   "source": [
    "# III) Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f71a68-2e7e-4e29-bf84-4d01b0876df9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dset_truncation.limit_length is None:\n",
    "    dset_truncation.limit_length = language_info[\"limit_length\"]\n",
    "else:\n",
    "    dset_truncation.limit_length = min(language_info[\"limit_length\"],dset_truncation.limit_length)\n",
    "    \n",
    "whole_dataset = dataset_mod.DatasetFromTxt(paths.path_dataset)\n",
    "\n",
    "idxs_whole = np.arange(dset_truncation.limit_length)\n",
    "dataset = torch.utils.data.Subset(whole_dataset,idxs_whole)\n",
    "\n",
    "dataset = list(dataset_mod.SentenceDataSet(dataset,sentence_type_src=sentence_mod.EnglishSentence,sentence_type_dst=sentence_mod.FrenchSentence))\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dfc062",
   "metadata": {
    "tags": []
   },
   "source": [
    "### IV) preparation of notebook params for serialization (for the purpose of associating the run to results of training), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aecd31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length_from_file = False\n",
    "if max_length_from_file:\n",
    "    max_length_french = language_info[\"french\"][\"max_sentence_train_val\"]\n",
    "    max_length_english = language_info[\"english\"][\"max_sentence_train_val\"]\n",
    "else:# get max length from current dataset, which is prefered\n",
    "    import itertools\n",
    "    tmp = [(len(el[0]),len(el[1])) for el in dataset]\n",
    "    a,b = zip(*tmp)\n",
    "    max_length_english  = max(a)\n",
    "    max_length_french = max(b)\n",
    "    \n",
    "max_length_english,max_length_french"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262c7d7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### V) dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14419b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remark : the responsability to split the dataset is done outside of this notebook\n",
    "from pathlib import Path\n",
    "\n",
    "if dset_truncation.use_splitting:\n",
    "    path_dataset_splitting = paths.path_dataset_splitting\n",
    "    path_idxs_train = str(Path(path_dataset_splitting).joinpath(\"idxs_train.npy\"))\n",
    "    path_idxs_val = str(Path(path_dataset_splitting).joinpath(\"idxs_val.npy\"))\n",
    "    path_idxs_test = str(Path(path_dataset_splitting).joinpath(\"idxs_test.npy\"))\n",
    "\n",
    "    idxs_train = np.load(path_idxs_train)\n",
    "    idxs_val = np.load(path_idxs_val)\n",
    "    idxs_test = np.load(path_idxs_test)\n",
    "\n",
    "    idxs_train,idxs_val,idxs_test = [[idx for idx in idxs if idx<len(whole_dataset)] for idxs in [idxs_train,idxs_val,idxs_test]]\n",
    "    idxs_train = list(set(idxs_whole).intersection(set(idxs_train)))\n",
    "    idxs_val = list(set(idxs_whole).intersection(set(idxs_val)))\n",
    "    idxs_test = list(set(idxs_whole).intersection(set(idxs_test)))\n",
    "    \n",
    "else:\n",
    "    idxs_train = idxs_whole\n",
    "    idxs_val = idxs_whole\n",
    "    idxs_test = idxs_whole\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset,idxs_train)\n",
    "val_dataset = torch.utils.data.Subset(dataset,idxs_val)\n",
    "test_dataset = torch.utils.data.Subset(dataset,idxs_test)\n",
    "len(train_dataset),len(val_dataset),len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb11c95",
   "metadata": {},
   "source": [
    "### VI) dataloader construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb015efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from translation_machine import collate_fn_mod\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "collate_fn = collate_fn_mod.get_collate_fn(max_length_english,max_length_french)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset,batch_size=simple_hp.batch_size,\n",
    "                               shuffle=True,collate_fn=collate_fn)\n",
    "val_data_loader = DataLoader(val_dataset,batch_size=simple_hp.batch_size,\n",
    "                             shuffle=True,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b32119b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import optim,nn\n",
    "\n",
    "\n",
    "baseline_loss = nn.CrossEntropyLoss(reduction=\"sum\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
