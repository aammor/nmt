{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22e6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translation_machine import dataset_utils\n",
    "\n",
    "import torchtext,torch\n",
    "from torchtext.datasets import Multi30k\n",
    "train_dataset = Multi30k(language_pair=(\"en\", \"de\"), split=('train'))\n",
    "train_dataset = dataset_utils.DatasetSlicer(train_dataset,start_index=0,stop_index=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968fb3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "de_tokenizer = get_tokenizer('spacy', language='de')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "from itertools import islice\n",
    "\n",
    "english_counter = Counter()\n",
    "german_counter = Counter()\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "for el in tqdm(train_dataset):\n",
    "    english_sentence = en_tokenizer(el[0])\n",
    "    german_sentence = de_tokenizer(el[1])\n",
    "    english_counter.update(english_sentence)\n",
    "    german_counter.update(german_sentence)\n",
    "\n",
    "\n",
    "vocab_english = torchtext.vocab.vocab(english_counter,specials=['<unk>'])\n",
    "vocab_german = torchtext.vocab.vocab(german_counter,specials=['<unk>','<sos>','<eos>'])\n",
    "\n",
    "vocab_english.set_default_index(vocab_english['<unk>'])\n",
    "vocab_german.set_default_index(vocab_german['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d24f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the tallest sequences for each language\n",
    "length_en_sentences = []\n",
    "length_de_sentrences = []\n",
    "for el in train_dataset:\n",
    "    length_en_sentences.append(len(el[0]))\n",
    "    length_de_sentrences.append(len(el[1]))\n",
    "max_length_english = max(length_de_sentrences)\n",
    "max_length_german = max(length_en_sentences)\n",
    "max_length_german_extended = max_length_german+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba07a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"transform batch of pairs of english and german sentences into batch tensor\"\"\"\n",
    "    en_id_tokens_batchs = []\n",
    "    ge_id_tokens_batchs = []\n",
    "    en_lengths = []\n",
    "    ge_lengths = []\n",
    "    for el in batch:\n",
    "        english_sentence,german_sentence = el\n",
    "        id_token_en = [vocab_english[el] for el in en_tokenizer(english_sentence)]\n",
    "        id_token_ge = [vocab_german[el] for el in de_tokenizer(german_sentence)]\n",
    "        en_length = len(id_token_en)\n",
    "        ge_length = len(id_token_ge)+2\n",
    "        \n",
    "        \n",
    "        id_token_en += [vocab_english['<unk>']]*(max_length_english-len(id_token_en))\n",
    "        id_token_ge = [vocab_german['<sos>']]+id_token_ge+[vocab_german['<eos>']]\n",
    "        id_token_ge += [vocab_german['<unk>']]*(max_length_german_extended-len(id_token_ge))\n",
    "        \n",
    "        #we add the start and en end of sequence token to each spanish sentence\n",
    "        \n",
    "        en_id_tokens_batchs.append(id_token_en)\n",
    "        ge_id_tokens_batchs.append(id_token_ge)\n",
    "        en_lengths.append(en_length)\n",
    "        ge_lengths.append(ge_length)\n",
    "\n",
    "    #convert to tensors\n",
    "    res =  en_id_tokens_batchs,ge_id_tokens_batchs,en_lengths,ge_lengths\n",
    "    res = [torch.tensor(el) for el in res]\n",
    "    \n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc1e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "shuffle = True\n",
    "batch_size= 20\n",
    "\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=shuffle,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afee296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translation_machine import model\n",
    "\n",
    "en_embeddings_size = 128\n",
    "ge_embeddings_size = 128\n",
    "\n",
    "hidden_size_encoder = 256\n",
    "hidden_size_decoder = 256\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_inputs = {\n",
    "    \"en_embeddings_size\":en_embeddings_size,\n",
    "    \"ge_embeddings_size\":ge_embeddings_size,\n",
    "    \"hidden_size_encoder\":hidden_size_encoder,\n",
    "    \"hidden_size_decoder\":hidden_size_decoder,\n",
    "    \"vocab_english\":vocab_english,\n",
    "    \"vocab_german\":vocab_german,\n",
    "    \"max_length_german_extended\":max_length_german_extended\n",
    "}\n",
    "\n",
    "sequence_translator = model.SequenceTranslator(**model_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "baseline_loss = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cddbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from translation_machine import model_trainer\n",
    "optimizer = optim.NAdam(params=sequence_translator.parameters(),lr=0.1)\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "model_trainer = model_trainer.ModelTrainer(sequence_translator,optimizer,scheduler,train_data_loader,None,baseline_loss)\n",
    "\n",
    "\n",
    "restart = True\n",
    "\n",
    "if not(restart):\n",
    "    tmp = torch.load(\"./sequence_translator_extended.pth\")\n",
    "    model_params = tmp[\"model_params\"]\n",
    "    model_inputs = tmp[\"model_inputs\"]\n",
    "    model_trainer.model.load_state_dict(model_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9002d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "sequence_translator.train()\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "bleu_scores_train = []\n",
    "bleu_scores_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3ec387",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 40\n",
    "\n",
    "for epoch in tqdm(range(nb_epochs)):\n",
    "    print(\"optimizing for epoch\")    \n",
    "    loss_train,bleu_score_train = model_trainer.train_on_epoch()\n",
    "    #loss_val,bleu_score_val = model_trainer.validate_on_epoch()\n",
    "\n",
    "    loss_train = [float(el) for el in loss_train]\n",
    "    #loss_val = [float(el) for el in loss_val]\n",
    "\n",
    "    losses_train.append(loss_train)\n",
    "    #losses_val.append(loss_val)\n",
    "    \n",
    "    #bleu_scores_train.append(bleu_score_train)\n",
    "    #bleu_scores_val.append(bleu_score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831f840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
