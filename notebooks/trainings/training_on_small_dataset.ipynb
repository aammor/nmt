{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c22e6baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aammor/miniforge3/envs/aa_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from translation_machine import dataset_utils\n",
    "\n",
    "import torchtext,torch\n",
    "from torchtext.datasets import Multi30k\n",
    "train_dataset = Multi30k(language_pair=(\"en\", \"de\"), split=('train'))\n",
    "train_dataset = dataset_utils.DatasetSlicer(train_dataset,start_index=0,stop_index=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968fb3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aammor/miniforge3/envs/aa_env/lib/python3.8/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"de\" could not be loaded, trying \"de_core_news_sm\" instead\n",
      "  warnings.warn(\n",
      "/Users/aammor/miniforge3/envs/aa_env/lib/python3.8/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "de_tokenizer = get_tokenizer('spacy', language='de')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871b3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 762.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "from itertools import islice\n",
    "\n",
    "english_counter = Counter()\n",
    "german_counter = Counter()\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "for el in tqdm(train_dataset):\n",
    "    english_sentence = en_tokenizer(el[0])\n",
    "    german_sentence = de_tokenizer(el[1])\n",
    "    english_counter.update(english_sentence)\n",
    "    german_counter.update(german_sentence)\n",
    "\n",
    "\n",
    "vocab_english = torchtext.vocab.vocab(english_counter,specials=['<unk>'])\n",
    "vocab_german = torchtext.vocab.vocab(german_counter,specials=['<unk>','<sos>','<eos>'])\n",
    "\n",
    "vocab_english.set_default_index(vocab_english['<unk>'])\n",
    "vocab_german.set_default_index(vocab_german['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d24f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the tallest sequences for each language\n",
    "length_en_sentences = []\n",
    "length_de_sentrences = []\n",
    "for el in train_dataset:\n",
    "    length_en_sentences.append(len(el[0]))\n",
    "    length_de_sentrences.append(len(el[1]))\n",
    "max_length_english = max(length_de_sentrences)\n",
    "max_length_german = max(length_en_sentences)\n",
    "max_length_german_extended = max_length_german+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba07a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"transform batch of pairs of english and german sentences into batch tensor\"\"\"\n",
    "    en_id_tokens_batchs = []\n",
    "    ge_id_tokens_batchs = []\n",
    "    en_lengths = []\n",
    "    ge_lengths = []\n",
    "    for el in batch:\n",
    "        english_sentence,german_sentence = el\n",
    "        id_token_en = [vocab_english[el] for el in en_tokenizer(english_sentence)]\n",
    "        id_token_ge = [vocab_german[el] for el in de_tokenizer(german_sentence)]\n",
    "        en_length = len(id_token_en)\n",
    "        ge_length = len(id_token_ge)+2\n",
    "        \n",
    "        \n",
    "        id_token_en += [vocab_english['<unk>']]*(max_length_english-len(id_token_en))\n",
    "        id_token_ge = [vocab_german['<sos>']]+id_token_ge+[vocab_german['<eos>']]\n",
    "        id_token_ge += [vocab_german['<unk>']]*(max_length_german_extended-len(id_token_ge))\n",
    "        \n",
    "        #we add the start and en end of sequence token to each spanish sentence\n",
    "        \n",
    "        en_id_tokens_batchs.append(id_token_en)\n",
    "        ge_id_tokens_batchs.append(id_token_ge)\n",
    "        en_lengths.append(en_length)\n",
    "        ge_lengths.append(ge_length)\n",
    "\n",
    "    #convert to tensors\n",
    "    res =  en_id_tokens_batchs,ge_id_tokens_batchs,en_lengths,ge_lengths\n",
    "    res = [torch.tensor(el) for el in res]\n",
    "    \n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65bc1e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "shuffle = True\n",
    "batch_size= 20\n",
    "\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=shuffle,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5afee296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translation_machine import model\n",
    "\n",
    "en_embeddings_size = 128\n",
    "ge_embeddings_size = 128\n",
    "\n",
    "hidden_size_encoder = 256\n",
    "hidden_size_decoder = 256\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_inputs = {\n",
    "    \"en_embeddings_size\":en_embeddings_size,\n",
    "    \"ge_embeddings_size\":ge_embeddings_size,\n",
    "    \"hidden_size_encoder\":hidden_size_encoder,\n",
    "    \"hidden_size_decoder\":hidden_size_decoder,\n",
    "    \"vocab_english\":vocab_english,\n",
    "    \"vocab_german\":vocab_german,\n",
    "    \"max_length_german_extended\":max_length_german_extended\n",
    "}\n",
    "\n",
    "sequence_translator = model.SequenceTranslator(**model_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7cf7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "baseline_loss = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3cddbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from translation_machine import model_trainer\n",
    "optimizer = optim.NAdam(params=sequence_translator.parameters(),lr=0.1)\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "model_trainer = model_trainer.ModelTrainer(sequence_translator,optimizer,scheduler,train_data_loader,None,baseline_loss)\n",
    "\n",
    "\n",
    "restart = True\n",
    "\n",
    "if not(restart):\n",
    "    tmp = torch.load(\"./sequence_translator_extended.pth\")\n",
    "    model_params = tmp[\"model_params\"]\n",
    "    model_inputs = tmp[\"model_inputs\"]\n",
    "    model_trainer.model.load_state_dict(model_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9002d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "sequence_translator.train()\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "bleu_scores_train = []\n",
    "bleu_scores_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3ec387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████▌                                                                             | 9/40 [00:00<00:00, 87.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizing for epoch\n",
      "3.3847692012786865 0\n",
      "optimizing for epoch\n",
      "0.6714446544647217 0\n",
      "optimizing for epoch\n",
      "0.3885660171508789 0\n",
      "optimizing for epoch\n",
      "0.2644120454788208 0\n",
      "optimizing for epoch\n",
      "0.04106639698147774 0\n",
      "optimizing for epoch\n",
      "0.005021213553845882 0\n",
      "optimizing for epoch\n",
      "0.0008707751403562725 0\n",
      "optimizing for epoch\n",
      "0.0006447559571824968 0\n",
      "optimizing for epoch\n",
      "0.0005386403645388782 0\n",
      "optimizing for epoch\n",
      "0.0004661052953451872 0\n",
      "optimizing for epoch\n",
      "0.0004128211585339159 0\n",
      "optimizing for epoch\n",
      "0.00037224372499622405 0\n",
      "optimizing for epoch\n",
      "0.0003405014576856047 0\n",
      "optimizing for epoch\n",
      "0.00031514704460278153 0\n",
      "optimizing for epoch\n",
      "0.0002945454325526953 0\n",
      "optimizing for epoch\n",
      "0.00027755493647418916 0\n",
      "optimizing for epoch\n",
      "0.00026344371144659817 0\n",
      "optimizing for epoch\n",
      "0.00025161984376609325 0\n",
      "optimizing for epoch\n",
      "0.0002416280476609245 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████████▊                           | 29/40 [00:00<00:00, 93.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizing for epoch\n",
      "0.00023319519823417068 0\n",
      "optimizing for epoch\n",
      "0.00022602344688493758 0\n",
      "optimizing for epoch\n",
      "0.00021990621462464333 0\n",
      "optimizing for epoch\n",
      "0.00021460522839333862 0\n",
      "optimizing for epoch\n",
      "0.00021007498435210437 0\n",
      "optimizing for epoch\n",
      "0.00020615085668396205 0\n",
      "optimizing for epoch\n",
      "0.0002027311857091263 0\n",
      "optimizing for epoch\n",
      "0.00019978104683104903 0\n",
      "optimizing for epoch\n",
      "0.0001972022873815149 0\n",
      "optimizing for epoch\n",
      "0.00019494231673888862 0\n",
      "optimizing for epoch\n",
      "0.0001929801655933261 0\n",
      "optimizing for epoch\n",
      "0.00019124228856526315 0\n",
      "optimizing for epoch\n",
      "0.00018970761448144913 0\n",
      "optimizing for epoch\n",
      "0.00018834456568583846 0\n",
      "optimizing for epoch\n",
      "0.00018713927420321852 0\n",
      "optimizing for epoch\n",
      "0.00018609862308949232 0\n",
      "optimizing for epoch\n",
      "0.000185156095540151 0\n",
      "optimizing for epoch\n",
      "0.0001843256613938138 0\n",
      "optimizing for epoch\n",
      "0.0001835863513406366 0\n",
      "optimizing for epoch\n",
      "0.00018292410823050886 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 94.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizing for epoch\n",
      "0.00018230742716696113 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 40\n",
    "\n",
    "for epoch in tqdm(range(nb_epochs)):\n",
    "    print(\"optimizing for epoch\")    \n",
    "    loss_train,bleu_score_train = model_trainer.train_on_epoch()\n",
    "    #loss_val,bleu_score_val = model_trainer.validate_on_epoch()\n",
    "\n",
    "    loss_train = [float(el) for el in loss_train]\n",
    "    #loss_val = [float(el) for el in loss_val]\n",
    "\n",
    "    losses_train.append(loss_train)\n",
    "    #losses_val.append(loss_val)\n",
    "    \n",
    "    #bleu_scores_train.append(bleu_score_train)\n",
    "    #bleu_scores_val.append(bleu_score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831f840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
