{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c39e4ff-d158-4b2f-801d-687247726209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "simple_hyp_params = argparse.Namespace(batch_size= 2,d_model = 32,\n",
    "early_stopping_activated = False,early_stop_steps_per_half_clr_cycle = 3,\n",
    "nb_epochs = 300)\n",
    "\n",
    "dset_truncation =argparse.Namespace(limit_length= 10,use_splitting = True,\n",
    "max_length_from_file = False)\n",
    "\n",
    "\n",
    "opt_params = argparse.Namespace(base_lr = 10**(-6),max_lr = 0.0005,\n",
    "momentum = 0.9,half_period_cycle = 5,\n",
    ")\n",
    "\n",
    "train_state_control = argparse.Namespace(load_from_backup = False,\n",
    "restore_from_backup = tuple([\"model_params\",\"scheduler\",\"optimizer\",\"losses\",\"metrics\"])\n",
    ")\n",
    "\n",
    "\n",
    "path_to_root = Path(\"../../\")\n",
    "\n",
    "paths = argparse.Namespace(path_dataset = \"data/french_english_dataset/fra.txt\",\n",
    "path_language_info = \"models/language_info.pth\",\n",
    "path_dataset_splitting = \"dataset_splitting\",\n",
    "path_model_and_dependencies = \"models/sequence_translator_transformer.pth\"\n",
    ")\n",
    "\n",
    "for key,path in paths.__dict__.items():\n",
    "    paths.__dict__[key] = str(path_to_root.joinpath(path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c67373-dd68-4524-b336-c20e333f12de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing cell: 12: 100%|███████████████████████| 19/19 [00:02<00:00,  7.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from ploomber_engine.ipython import PloomberClient\n",
    "from ploomber.tasks import NotebookRunner\n",
    "from ploomber import DAG\n",
    "from pathlib import Path\n",
    "from ploomber.products import File\n",
    "\n",
    "# initialize client\n",
    "client = PloomberClient.from_path(Path(\"./training_setup.ipynb\"))\n",
    "from argparse import Namespace\n",
    "\n",
    "from translation_machine.models import transformer_mod\n",
    "from translation_machine import sentence_mod\n",
    "\n",
    "initial_namespace = argparse.Namespace(**{key:globals()[key] for key in [\"simple_hyp_params\",\"dset_truncation\",\n",
    "                                                  \"opt_params\",\"train_state_control\",\n",
    "                                                  \"paths\"]})\n",
    "\n",
    "train_setup = client.get_namespace(initial_namespace.__dict__)\n",
    "for key,val in train_setup.items():\n",
    "    globals()[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f43be39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizing for epoch 0\n",
      "training_step\n",
      "0 7.143755594889323\n",
      "validation_step\n",
      "0 7.198941230773926\n",
      "saving for epoch 0\n",
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/300 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_loss_val_mean = np.inf\n",
    "best_epoch = scheduler.last_epoch\n",
    "\n",
    "for epoch in tqdm(range(simple_hyp_params.nb_epochs)):\n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    print(f\"optimizing for epoch {epoch}\")\n",
    "    print(\"training_step\")\n",
    "    loss_train,nb_words_per_batch_train,metric_train = model_trainer.train_on_epoch()\n",
    "    \n",
    "    print(\"validation_step\")\n",
    "    loss_val,nb_words_per_batch_val,metric_val = model_trainer.validate_on_epoch()\n",
    "\n",
    "    loss_train = np.array([float(el) for el in loss_train])\n",
    "    loss_val = np.array([float(el) for el in loss_val])\n",
    "    train_weights = 1/sum(nb_words_per_batch_train)\n",
    "    val_weights = 1/sum(nb_words_per_batch_val)\n",
    "    \n",
    "    \n",
    "        \n",
    "    losses[\"train\"].append(np.sum(loss_train)/sum(nb_words_per_batch_train))\n",
    "    losses[\"val\"].append(np.sum(loss_val)/sum(nb_words_per_batch_val))\n",
    "    metrics[\"train\"].append(metric_train)\n",
    "    metrics[\"val\"].append(metric_val)\n",
    "    \n",
    "    current_loss_val_mean = np.mean(loss_val)\n",
    "    if (current_loss_val_mean < best_loss_val_mean):\n",
    "        best_epoch = scheduler.last_epoch\n",
    "        best_loss_val_mean = current_loss_val_mean\n",
    "\n",
    "        model_training_state = {\"model_params\":model_trainer.model.state_dict(),\n",
    "                               \"model_inputs\":model_inputs,\n",
    "                              \"optimizer\":optimizer.state_dict(),\n",
    "                              \"scheduler\":scheduler.state_dict(),\n",
    "                              \"losses\":losses,\n",
    "                              \"metrics\":metrics\n",
    "                              }\n",
    "        \n",
    "        torch.save(model_training_state,path_model_and_dependencies)\n",
    "        print(f\"saving for epoch {epoch}\")\n",
    "\n",
    "        plt.plot(losses[\"train\"],\"b*\")\n",
    "        plt.plot(losses[\"val\"],\"g*\")\n",
    "        plt.title(\"losses\")\n",
    "        plt.show()\n",
    "        break\n",
    "        #import pdb;pdb.set_trace()\n",
    "    elif epoch - best_epoch > early_stop_thresh  and early_stopping_activated:\n",
    "        print(\"Early stopped training at epoch %d\" % epoch)\n",
    "        break  # terminate the training loop\n",
    "    #stop = time.time()\n",
    "    #print(stop-start)\n",
    "\n",
    "    del loss_train,nb_words_per_batch_train,metric_train\n",
    "\n",
    "    del loss_val,nb_words_per_batch_val,metric_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2571b27e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses[\"train\"],\"b*\")\n",
    "plt.plot(losses[\"val\"],\"g*\")\n",
    "plt.title(\"losses\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ad7d1-f074-4de9-b6f4-625fde773ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
