{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c39e4ff-d158-4b2f-801d-687247726209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch,inspect\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "from dev import namespace_tools\n",
    "# nested namespace arguement containing all elements associated to the training setup\n",
    "\n",
    "notebook_run = Namespace(\n",
    "    simple_hp = Namespace(\n",
    "        batch_size= 32,\n",
    "        d_model = 64,\n",
    "        early_stop_thresh = np.inf, # default to np.inf\n",
    "        nb_epochs = 10,\n",
    "        warm_up_epochs = 20,\n",
    "    ),\n",
    "    # parameters to limit the size of the dataset\n",
    "    dset_truncation = Namespace(\n",
    "        limit_length= 15,\n",
    "        use_splitting = False,\n",
    "        max_length_from_file = False,\n",
    "    ),\n",
    "    # parameters for the optimization algorithm\n",
    "    opt_params = Namespace(\n",
    "        unlinked_optimizer = partial(torch.optim.NAdam,lr=0.01),\n",
    "        unlinked_scheduler = partial(torch.optim.lr_scheduler.ReduceLROnPlateau, mode='min', \n",
    "                                     factor=0.9, patience=20)\n",
    "    ),\n",
    "    # parameters to reload the model\n",
    "    train_state_control = Namespace(             \n",
    "        load_from_backup = False,\n",
    "        restore_optimizer = False\n",
    "    ),\n",
    "    #paths from root\n",
    "    paths = namespace_tools.Paths(\n",
    "        path_dataset = \"data/french_english_dataset/fra.txt\",\n",
    "        path_language_info = \"models/language_info.pth\",\n",
    "        path_dataset_splitting = \"dataset_splitting\",\n",
    "        path_model_and_dependencies = \"models/sequence_translator_transformer_over_fitted.pth\",\n",
    "        root = \"../..\"\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18e34688-f0a4-4e6f-9a17-2ecd7ff351f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_run = namespace_tools.NameSpaceAggregation(notebook_run)\n",
    "notebook_run.diffuse(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95c67373-dd68-4524-b336-c20e333f12de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing cell: 13: 100%|███████████████████████| 21/21 [00:00<00:00, 82.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from ploomber_engine.ipython import PloomberClient\n",
    "from ploomber import DAG\n",
    "from pathlib import Path\n",
    "from ploomber.products import File\n",
    "\n",
    "# initialize client\n",
    "client = PloomberClient.from_path(Path(\"./training_setup.ipynb\"),cwd=Path(\"../../\"))\n",
    "from argparse import Namespace\n",
    "\n",
    "from translation_machine.models import transformer_mod\n",
    "from translation_machine import sentence_mod\n",
    "\n",
    "initial_namespace_as_dict = notebook_run.diffuse()\n",
    "train_setup = client.get_namespace(initial_namespace_as_dict)\n",
    "for key,val in train_setup.items():\n",
    "        globals()[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "683d6670-c590-4d63-af90-4a57d1a75b08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# revert to train mode\n",
    "model.train()\n",
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaa421e9-c523-4f00-a33a-e5a3e7ee6f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from translation_machine import model_trainer_mod\n",
    "model_trainer = model_trainer_mod.ModelTrainer(model,optimizer,train_data_loader,val_data_loader,baseline_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81186763-87ae-4871-9dbc-9271a83c9f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 0\n",
      "for epoch 0 learning rate is 0.01\n",
      "training_step\n",
      "0 8.863941192626953\n",
      "validation_step\n",
      "0 9.079339345296225\n",
      "for epoch 0 mean loss on train 8.863941192626953\n",
      "for epoch 0 mean loss on val 9.079339027404785\n",
      "saving for epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████                                                               | 1/10 [00:01<00:11,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 1\n",
      "for epoch 1 learning rate is 0.01\n",
      "training_step\n",
      "0 9.138506571451822\n",
      "validation_step\n",
      "0 8.865436553955078\n",
      "for epoch 1 mean loss on train 9.138506889343262\n",
      "for epoch 1 mean loss on val 8.865436553955078\n",
      "saving for epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████                                                        | 2/10 [00:01<00:05,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 2\n",
      "for epoch 2 learning rate is 0.01\n",
      "training_step\n",
      "0 9.06058438618978\n",
      "validation_step\n",
      "0 8.833587646484375\n",
      "for epoch 2 mean loss on train 9.06058406829834\n",
      "for epoch 2 mean loss on val 8.833587646484375\n",
      "saving for epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████                                                 | 3/10 [00:01<00:03,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 3\n",
      "for epoch 3 learning rate is 0.01\n",
      "training_step\n",
      "0 8.700008392333984\n",
      "validation_step\n",
      "0 9.12891960144043\n",
      "for epoch 3 mean loss on train 8.700008392333984\n",
      "for epoch 3 mean loss on val 9.12891960144043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████                                          | 4/10 [00:02<00:02,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 4\n",
      "for epoch 4 learning rate is 0.01\n",
      "training_step\n",
      "0 8.88258425394694\n",
      "validation_step\n",
      "0 8.741373697916666\n",
      "for epoch 4 mean loss on train 8.882584571838379\n",
      "for epoch 4 mean loss on val 8.741374015808105\n",
      "saving for epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████                                   | 5/10 [00:02<00:01,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 5\n",
      "for epoch 5 learning rate is 0.01\n",
      "training_step\n",
      "0 9.156496047973633\n",
      "validation_step\n",
      "0 8.795818328857422\n",
      "for epoch 5 mean loss on train 9.156496047973633\n",
      "for epoch 5 mean loss on val 8.795818328857422\n",
      "training for epoch 6\n",
      "for epoch 6 learning rate is 0.01\n",
      "training_step\n",
      "0 8.810162862141928\n",
      "validation_step\n",
      "0 8.958353042602539\n",
      "for epoch 6 mean loss on train 8.810162544250488\n",
      "for epoch 6 mean loss on val 8.958353042602539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████                     | 7/10 [00:02<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 7\n",
      "for epoch 7 learning rate is 0.01\n",
      "training_step\n",
      "0 9.013396581013998\n",
      "validation_step\n",
      "0 9.0629030863444\n",
      "for epoch 7 mean loss on train 9.013396263122559\n",
      "for epoch 7 mean loss on val 9.06290340423584\n",
      "training for epoch 8\n",
      "for epoch 8 learning rate is 0.01\n",
      "training_step\n",
      "0 8.847869237263998\n",
      "validation_step\n",
      "0 9.078512191772461\n",
      "for epoch 8 mean loss on train 8.847868919372559\n",
      "for epoch 8 mean loss on val 9.078512191772461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████       | 9/10 [00:02<00:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 9\n",
      "for epoch 9 learning rate is 0.01\n",
      "training_step\n",
      "0 8.871288299560547\n",
      "validation_step\n",
      "0 9.224248250325521\n",
      "for epoch 9 mean loss on train 8.871288299560547\n",
      "for epoch 9 mean loss on val 9.224247932434082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.59it/s]\n"
     ]
    }
   ],
   "source": [
    "## import matplotlib.pyplot as plt,numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "best_loss_val_mean = np.inf\n",
    "best_epoch = scheduler.last_epoch\n",
    "\n",
    "for epoch in tqdm(range(simple_hp.nb_epochs)):\n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    print(f\"training for epoch {epoch}\")\n",
    "    print(f\"for epoch {epoch} learning rate is {optimizer.param_groups[0]['lr']}\" )\n",
    "    print(\"training_step\")\n",
    "    loss_train,nb_words_per_batch_train,metric_train = model_trainer.train_on_epoch()\n",
    "    print(\"validation_step\")\n",
    "    loss_val,nb_words_per_batch_val,metric_val = model_trainer.validate_on_epoch()\n",
    "\n",
    "    sum_loss_train = torch.tensor(loss_train).sum()\n",
    "    sum_loss_val = torch.tensor(loss_val).sum()\n",
    "    mean_train_loss = sum_loss_train/sum(nb_words_per_batch_train)\n",
    "    mean_val_loss = sum_loss_val/sum(nb_words_per_batch_val)\n",
    "\n",
    "    scheduler.step(mean_val_loss)\n",
    "\n",
    "        \n",
    "    print(f\"for epoch {epoch} mean loss on train {mean_train_loss}\")\n",
    "    print(f\"for epoch {epoch} mean loss on val {mean_val_loss}\")\n",
    "        \n",
    "    losses[\"train\"].append(mean_train_loss)\n",
    "    losses[\"val\"].append(mean_val_loss)\n",
    "    metrics[\"train\"].append(metric_train)\n",
    "    metrics[\"val\"].append(metric_val)\n",
    "    \n",
    "    if (mean_val_loss < best_loss_val_mean):\n",
    "        best_epoch = scheduler.last_epoch\n",
    "        best_loss_val_mean = mean_val_loss\n",
    "\n",
    "        model_training_state = {\"model_params\":model_trainer.model.state_dict(),\n",
    "                               \"model_inputs\":model_inputs,\n",
    "                              \"optimizer\":optimizer.state_dict(),\n",
    "                              \"scheduler\":scheduler.state_dict(),\n",
    "                              }\n",
    "        results = { \"losses\":losses,\n",
    "                   \"metrics\":metrics}\n",
    "        new_back_up = dict()\n",
    "        if \"back_up\" in globals():\n",
    "            new_back_up[\"notebook_runs\"] = back_up[\"notebook_runs\"] + tuple([notebook_run.state_dict()])\n",
    "        else:\n",
    "            new_back_up[\"notebook_runs\"] = tuple([notebook_run.state_dict()])\n",
    "\n",
    "        new_back_up[\"results\"] = results\n",
    "        new_back_up[\"model_training_state\"] = model_training_state\n",
    "        \n",
    "        back_up = new_back_up\n",
    "        torch.save(back_up,paths.path_model_and_dependencies)\n",
    "        print(f\"saving for epoch {epoch}\")\n",
    "        \n",
    "        plt.plot(losses[\"train\"],\"b*\")\n",
    "        plt.plot(losses[\"val\"],\"g*\")\n",
    "        plt.title(\"losses\")\n",
    "        plt.savefig(\"loss_curve\")\n",
    "        #import pdb;pdb.set_trace()\n",
    "    elif epoch - best_epoch > simple_hp.early_stop_thresh  and epoch > simple_hp.warm_up_epochs:\n",
    "        print(\"Early stopped training at epoch %d\" % epoch)\n",
    "        break  # terminate the training loop\n",
    "\n",
    "    del loss_train,nb_words_per_batch_train,metric_train\n",
    "\n",
    "    del loss_val,nb_words_per_batch_val,metric_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65534f86-14db-4c08-96f2-a7e72aa860d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 2]), torch.Size([1, 4]), torch.Size([1]), torch.Size([1])]\n"
     ]
    }
   ],
   "source": [
    "for el in model_trainer.train_data_loader:\n",
    "    print([el1.shape for el1 in el])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571b27e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(results[\"losses\"][\"train\"],\"b*\")\n",
    "plt.plot(results[\"losses\"][\"val\"],\"g*\")\n",
    "plt.title(\"losses\")\n",
    "plt.savefig(f'test.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528ee66-f8f0-4682-be19-098ab5b8854f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
