{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c39e4ff-d158-4b2f-801d-687247726209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "batch_size= 32\n",
    "d_model = 512\n",
    "early_stopping_activated = True\n",
    "early_stop_steps_per_half_clr_cycle = 10\n",
    "nb_epochs = 200\n",
    "\n",
    "limit_length= None\n",
    "use_splitting = True\n",
    "max_length_from_file = False\n",
    "\n",
    "\n",
    "base_lr = 10**(-6)\n",
    "max_lr = 0.001\n",
    "momentum = 0.9\n",
    "half_period_cycle = 10\n",
    "gamma = 0.8\n",
    "\n",
    "load_from_backup = False\n",
    "restore_from_backup = tuple([\"model_params\",\"scheduler\",\"optimizer\",\"losses\",\"metrics\"])\n",
    "\n",
    "simple_hyp_params = argparse.Namespace(batch_size= batch_size,d_model = d_model,\n",
    "early_stopping_activated = early_stopping_activated,\n",
    "early_stop_steps_per_half_clr_cycle = early_stop_steps_per_half_clr_cycle,\n",
    "nb_epochs = nb_epochs)\n",
    "\n",
    "dset_truncation =argparse.Namespace(limit_length= limit_length,\n",
    "                                    use_splitting = use_splitting,\n",
    "                                    max_length_from_file = max_length_from_file)\n",
    "\n",
    "\n",
    "opt_params = argparse.Namespace(base_lr = base_lr,\n",
    "                                max_lr = max_lr,\n",
    "                                momentum = momentum,\n",
    "                                half_period_cycle = half_period_cycle,\n",
    "                               gamma=gamma)\n",
    "\n",
    "train_state_control = argparse.Namespace(load_from_backup = load_from_backup,\n",
    "restore_from_backup = restore_from_backup\n",
    ")\n",
    "\n",
    "\n",
    "path_to_root = Path(\"../../\")\n",
    "\n",
    "paths = argparse.Namespace(path_dataset = \"data/french_english_dataset/fra.txt\",\n",
    "path_language_info = \"models/language_info.pth\",\n",
    "path_dataset_splitting = \"dataset_splitting\",\n",
    "path_model_and_dependencies = \"models/sequence_translator_transformer_new.pth\"\n",
    ")\n",
    "\n",
    "for key,path in paths.__dict__.items():\n",
    "    paths.__dict__[key] = str(path_to_root.joinpath(path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c67373-dd68-4524-b336-c20e333f12de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amine_ammor_91/miniconda3/envs/nmt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Executing cell: 12: 100%|███████████████████████| 19/19 [00:03<00:00,  5.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from ploomber_engine.ipython import PloomberClient\n",
    "from ploomber import DAG\n",
    "from pathlib import Path\n",
    "from ploomber.products import File\n",
    "\n",
    "# initialize client\n",
    "client = PloomberClient.from_path(Path(\"./training_setup.ipynb\"))\n",
    "from argparse import Namespace\n",
    "\n",
    "from translation_machine.models import transformer_mod\n",
    "from translation_machine import sentence_mod\n",
    "\n",
    "initial_namespace = argparse.Namespace(**{key:globals()[key] for key in [\"simple_hyp_params\",\"dset_truncation\",\n",
    "                                                  \"opt_params\",\"train_state_control\",\n",
    "                                                  \"paths\"]})\n",
    "train_setup = client.get_namespace(initial_namespace.__dict__)\n",
    "for key,val in train_setup.items():\n",
    "        globals()[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81186763-87ae-4871-9dbc-9271a83c9f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 0\n",
      "for epoch 0 learning rate is 1e-06\n",
      "training_step\n",
      "0 6.687884852216749\n",
      "100 5.323258503828899\n",
      "200 5.010234102289727\n",
      "300 4.5811552531978625\n",
      "400 4.58891304132297\n",
      "validation_step\n",
      "0 4.412269701797997\n",
      "for epoch 0 mean loss on train 4.938881250013578\n",
      "for epoch 0 mean loss on val 4.240734629012119\n",
      "saving for epoch 0\n",
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                               | 1/200 [00:55<3:03:53, 55.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 1\n",
      "for epoch 1 learning rate is 8.092000000000009e-05\n",
      "training_step\n",
      "0 4.298705435041244\n",
      "100 2.9251587553174083\n",
      "200 2.329769095989189\n",
      "300 2.079179349152938\n",
      "400 2.0220182002498412\n",
      "validation_step\n",
      "0 1.9919254363529266\n",
      "for epoch 1 mean loss on train 2.410864146081984\n",
      "for epoch 1 mean loss on val 1.8487869126336371\n",
      "saving for epoch 1\n",
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                               | 2/200 [01:50<3:01:47, 55.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 2\n",
      "for epoch 2 learning rate is 0.00012887200000000014\n",
      "training_step\n",
      "0 1.6733774768256153\n",
      "100 1.7759250779226037\n",
      "200 1.6018329376870013\n",
      "300 1.543948301334971\n",
      "400 1.3310269725566009\n",
      "validation_step\n",
      "0 1.4836842346191406\n",
      "for epoch 2 mean loss on train 1.5568904796649858\n",
      "for epoch 2 mean loss on val 1.3689830655965014\n",
      "saving for epoch 2\n",
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▏                                                                              | 3/200 [02:44<2:59:49, 54.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 3\n",
      "for epoch 3 learning rate is 0.00015444639999999995\n",
      "training_step\n",
      "0 1.3402431120122145\n",
      "100 0.8327610355397169\n",
      "200 1.0389971051897322\n",
      "300 0.9737141678972943\n",
      "400 1.0873854312990687\n",
      "validation_step\n",
      "0 1.0268258163609456\n",
      "for epoch 3 mean loss on train 1.1602130076571917\n",
      "for epoch 3 mean loss on val 1.1519184296968707\n",
      "saving for epoch 3\n",
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                              | 4/200 [03:39<2:59:05, 54.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 4\n",
      "for epoch 4 learning rate is 0.00016467616\n",
      "training_step\n",
      "0 1.0072544415791829\n",
      "100 0.9475847746196546\n",
      "200 0.7232176765562996\n",
      "300 0.7673772446652676\n",
      "400 0.7653746511421952\n",
      "validation_step\n",
      "0 0.8349850562310988\n",
      "for epoch 4 mean loss on train 0.9325389186161376\n",
      "for epoch 4 mean loss on val 1.012742920212476\n",
      "saving for epoch 4\n",
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                              | 5/200 [04:34<2:58:03, 54.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 5\n",
      "for epoch 5 learning rate is 0.00016467616000000006\n",
      "training_step\n",
      "0 0.7249169158935547\n",
      "100 0.7163392745237299\n",
      "200 0.9954613905686599\n",
      "300 1.133708452937579\n",
      "400 0.6422796694108241\n",
      "validation_step\n",
      "0 0.994787166255931\n",
      "for epoch 5 mean loss on train 0.8550141770445625\n",
      "for epoch 5 mean loss on val 0.9507036815456655\n",
      "saving for epoch 5\n",
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                             | 6/200 [05:29<2:57:08, 54.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 6\n",
      "for epoch 6 learning rate is 0.00015812911360000008\n",
      "training_step\n",
      "0 0.8627910614013672\n",
      "100 0.677917847266564\n",
      "200 0.7146240234375\n",
      "300 0.7027748682165659\n",
      "400 0.6744446267887038\n",
      "validation_step\n",
      "0 0.9198189544677734\n",
      "for epoch 6 mean loss on train 0.6984789532284229\n",
      "for epoch 6 mean loss on val 0.9199647950944473\n",
      "saving for epoch 6\n",
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▊                                                                             | 7/200 [06:23<2:56:12, 54.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 7\n",
      "for epoch 7 learning rate is 0.0001476538393600001\n",
      "training_step\n",
      "0 0.6755851951805321\n",
      "100 0.6216876109441122\n",
      "200 0.6108562313780492\n",
      "300 0.7913542468138416\n",
      "400 0.5036589632329252\n",
      "validation_step\n",
      "0 1.1906116428087705\n",
      "for epoch 7 mean loss on train 0.6126266432937806\n",
      "for epoch 7 mean loss on val 0.8856198243510852\n",
      "saving for epoch 7\n",
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                            | 8/200 [07:18<2:55:13, 54.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 8\n",
      "for epoch 8 learning rate is 0.00013508351027200006\n",
      "training_step\n",
      "0 0.5600748910953861\n",
      "100 0.5239521695166519\n",
      "200 0.6405175052472015\n",
      "300 0.6320497581995831\n",
      "400 0.5926768861967942\n",
      "validation_step\n",
      "0 0.7073931012834821\n",
      "for epoch 8 mean loss on train 0.5478366265093335\n",
      "for epoch 8 mean loss on val 0.8645535040698092\n",
      "saving for epoch 8\n",
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                            | 9/200 [08:13<2:54:13, 54.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 9\n",
      "for epoch 9 learning rate is 0.00012167515924480006\n",
      "training_step\n",
      "0 0.45079340253557476\n",
      "100 0.47847571161580205\n",
      "200 0.5690623515361064\n",
      "300 0.6224572945639725\n",
      "400 0.5460664684645795\n",
      "validation_step\n",
      "0 0.6642640080284233\n",
      "for epoch 9 mean loss on train 0.4894368508050305\n",
      "for epoch 9 mean loss on val 0.8519559142668507\n",
      "saving for epoch 9\n",
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▉                                                                           | 10/200 [09:08<2:53:42, 54.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 10\n",
      "for epoch 10 learning rate is 0.00010826680821760007\n",
      "training_step\n",
      "0 0.36259286870401375\n",
      "100 0.39970842997233075\n",
      "200 0.507964120784276\n",
      "300 0.46983822225937116\n",
      "400 0.4310407980894431\n",
      "validation_step\n",
      "0 0.7066648809403335\n",
      "for epoch 10 mean loss on train 0.4402346180254814\n",
      "for epoch 10 mean loss on val 0.8341467321146069\n",
      "saving for epoch 10\n",
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▎                                                                          | 11/200 [10:04<2:53:50, 55.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 11\n",
      "for epoch 11 learning rate is 7.823210191667205e-05\n",
      "training_step\n",
      "0 0.3724473610902444\n",
      "100 0.34589830714853564\n",
      "200 0.3318704907359973\n",
      "300 0.29352344936794705\n",
      "400 0.3649669158153045\n",
      "validation_step\n",
      "0 0.8151100354316907\n",
      "for epoch 11 mean loss on train 0.3751612481664923\n",
      "for epoch 11 mean loss on val 0.8257456756287783\n",
      "saving for epoch 11\n",
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▋                                                                          | 12/200 [11:01<2:54:28, 55.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for epoch 12\n",
      "for epoch 12 learning rate is 5.592060580741122e-05\n",
      "training_step\n",
      "0 0.29035984019123057\n",
      "100 0.2965439126846638\n",
      "200 0.27447339784296065\n",
      "300 0.3659014250102796\n",
      "400 0.3410817302724041\n"
     ]
    }
   ],
   "source": [
    "## import matplotlib.pyplot as plt,numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "best_loss_val_mean = np.inf\n",
    "best_epoch = scheduler.last_epoch\n",
    "\n",
    "for epoch in tqdm(range(simple_hyp_params.nb_epochs)):\n",
    "    #import time\n",
    "    #start = time.time()\n",
    "    print(f\"training for epoch {epoch}\")\n",
    "\n",
    "    print(f\"for epoch {epoch} learning rate is {optimizer.param_groups[0]['lr']}\" )\n",
    "\n",
    "    print(\"training_step\")\n",
    "    loss_train,nb_words_per_batch_train,metric_train = model_trainer.train_on_epoch()\n",
    "    \n",
    "    print(\"validation_step\")\n",
    "    loss_val,nb_words_per_batch_val,metric_val = model_trainer.validate_on_epoch()\n",
    "\n",
    "    loss_train = np.array([float(el) for el in loss_train])\n",
    "    loss_val = np.array([float(el) for el in loss_val])\n",
    "    mean_train_loss = np.sum(loss_train)/sum(nb_words_per_batch_train)\n",
    "    mean_val_loss = np.sum(loss_val)/sum(nb_words_per_batch_val)\n",
    "    \n",
    "    print(f\"for epoch {epoch} mean loss on train {mean_train_loss}\")\n",
    "    print(f\"for epoch {epoch} mean loss on val {mean_val_loss}\")\n",
    "        \n",
    "    losses[\"train\"].append(mean_train_loss)\n",
    "    losses[\"val\"].append(mean_val_loss)\n",
    "    metrics[\"train\"].append(metric_train)\n",
    "    metrics[\"val\"].append(metric_val)\n",
    "    \n",
    "    current_loss_val_mean = np.mean(loss_val)\n",
    "    if (current_loss_val_mean < best_loss_val_mean):\n",
    "        best_epoch = model_trainer.scheduler.last_epoch\n",
    "        best_loss_val_mean = current_loss_val_mean\n",
    "\n",
    "        model_training_state = {\"model_params\":model_trainer.model.state_dict(),\n",
    "                               \"model_inputs\":model_inputs,\n",
    "                              \"optimizer\":optimizer.state_dict(),\n",
    "                              \"scheduler\":scheduler.state_dict(),\n",
    "                              \"losses\":losses,\n",
    "                              \"metrics\":metrics\n",
    "                              }\n",
    "        \n",
    "        torch.save(model_training_state,path_model_and_dependencies)\n",
    "        print(f\"saving for epoch {epoch}\")\n",
    "        \n",
    "        \n",
    "        plt.plot(losses[\"train\"],\"b*\")\n",
    "        plt.plot(losses[\"val\"],\"g*\")\n",
    "        plt.title(\"losses\")\n",
    "        plt.show()\n",
    "        #import pdb;pdb.set_trace()\n",
    "    elif epoch - best_epoch > simple_hyp_params.early_stop_thresh  and early_stopping_activated:\n",
    "        print(\"Early stopped training at epoch %d\" % epoch)\n",
    "        break  # terminate the training loop\n",
    "    #stop = time.time()\n",
    "    #print(stop-start)\n",
    "\n",
    "    del loss_train,nb_words_per_batch_train,metric_train\n",
    "\n",
    "    del loss_val,nb_words_per_batch_val,metric_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571b27e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses[\"train\"],\"b*\")\n",
    "plt.plot(losses[\"val\"],\"g*\")\n",
    "plt.title(\"losses\")\n",
    "plt.savefig(f'test_{batch_size}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759b39e-a220-473b-b55b-d542444358c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.min(losses[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221250f5-7a7c-432c-a934-bd77b75be6da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
